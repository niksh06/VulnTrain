#!/usr/bin/env python3
"""
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –∞–Ω–∞–ª–∏–∑–∞ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –∏ –º–æ–¥–µ–ª–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –≤–µ—Ä—Å–∏—è –±–µ–∑ —Å–µ–∫—Ä–µ—Ç–æ–≤
"""

import json
from typing import List, Dict, Any

def load_security_summary():
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–≤–æ–¥–∫–∏ –ø–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"""
    try:
        with open('security_datasets_summary.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        return None

def print_summary():
    """–í—ã–≤–æ–¥ —Å–≤–æ–¥–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    data = load_security_summary()
    if not data:
        print("‚ùå –§–∞–π–ª security_datasets_summary.json –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    print("üîç –ê–ù–ê–õ–ò–ó –î–ê–¢–ê–°–ï–¢–û–í –ò –ú–û–î–ï–õ–ï–ô –ò–ù–§–û–†–ú–ê–¶–ò–û–ù–ù–û–ô –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò")
    print("=" * 70)
    
    summary = data['summary']
    print(f"\nüìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"   üìà –í—Å–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤: {summary['total_datasets']:,}")
    print(f"   ü§ñ –í—Å–µ–≥–æ –º–æ–¥–µ–ª–µ–π: {summary['total_models']:,}")
    print(f"   üîí –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤: {summary['security_datasets']:,}")
    print(f"   üõ°Ô∏è –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π: {summary['security_models']:,}")
    print(f"   üìÖ –î–∞—Ç–∞ –ø–æ–∏—Å–∫–∞: {summary['search_date']}")
    
    print(f"\nüìä –ö–ê–¢–ï–ì–û–†–ò–ò –î–ê–¢–ê–°–ï–¢–û–í:")
    for category, count in data['categories']['datasets'].items():
        print(f"   {category.replace('_', ' ').title()}: {count}")
    
    print(f"\nü§ñ –ö–ê–¢–ï–ì–û–†–ò–ò –ú–û–î–ï–õ–ï–ô:")
    for category, count in data['categories']['models'].items():
        print(f"   {category.replace('_', ' ').title()}: {count}")
    
    print(f"\nüèÜ –¢–û–ü –î–ê–¢–ê–°–ï–¢–´ –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:")
    for category, datasets in data['top_datasets'].items():
        print(f"\n   {category.replace('_', ' ').upper()}:")
        for i, dataset in enumerate(datasets[:5], 1):
            print(f"     {i}. {dataset}")
    
    print(f"\nü§ñ –¢–û–ü –ú–û–î–ï–õ–ò –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:")
    for category, models in data['top_models'].items():
        print(f"\n   {category.replace('_', ' ').upper()}:")
        for i, model in enumerate(models[:5], 1):
            print(f"     {i}. {model}")
    
    print(f"\nüéØ –†–ï–°–£–†–°–´ CIRCL:")
    print(f"   üìä –î–∞—Ç–∞—Å–µ—Ç—ã:")
    for dataset in data['circl_resources']['datasets']:
        print(f"     - {dataset}")
    
    print(f"   ü§ñ –ú–æ–¥–µ–ª–∏:")
    for model in data['circl_resources']['models']:
        print(f"     - {model}")

def print_download_commands():
    """–í—ã–≤–æ–¥ –∫–æ–º–∞–Ω–¥ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏"""
    data = load_security_summary()
    if not data:
        return
    
    print(f"\nüì• –ö–û–ú–ê–ù–î–´ –î–õ–Ø –ó–ê–ì–†–£–ó–ö–ò:")
    print(f"\nüîí –¢–û–ü –î–ê–¢–ê–°–ï–¢–´ CIRCL:")
    for dataset in data['circl_resources']['datasets']:
        print(f"huggingface-cli download {dataset}")
    
    print(f"\nü§ñ –¢–û–ü –ú–û–î–ï–õ–ò –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò:")
    for model in data['top_models']['generation'][:3]:
        print(f"huggingface-cli download {model}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print_summary()
    print_download_commands()
    
    print(f"\nüí° –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï:")
    print(f"   üìñ –ü–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç: final_security_report.md")
    print(f"   üìã –ö—Ä–∞—Ç–∫–∏–π –æ–±–∑–æ—Ä: top10_summary.md")
    print(f"   üìö –ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: SECURITY_ANALYSIS_README.md")
    print(f"   üîß VulnTrain –∫–æ–º–∞–Ω–¥—ã:")
    print(f"      pip install vulntrain[all]")
    print(f"      vulntrain-dataset-generation --sources cvelistv5,ghsa --nb-rows 1000000")

if __name__ == "__main__":
    main()